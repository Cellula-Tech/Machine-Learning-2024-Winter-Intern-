{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GZ-TjTRiRblu"},"outputs":[],"source":["!pip install flask-cors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16699,"status":"ok","timestamp":1727957401438,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"1Q1xiQm9SS7y","outputId":"f7380b19-3530-4c3d-ce99-7a3a6c59e343"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.0\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":2538,"status":"error","timestamp":1727983010243,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"8lXPJ90e50Cl"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.feature_selection import RFECV\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","import joblib\n","from flask import Flask, request, jsonify\n","from flask_cors import CORS\n","from pyngrok import ngrok\n","import threading\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":752,"status":"ok","timestamp":1727969824555,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"aWIeYhe-5_Mw"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-4-45f683a2eb1a\u003e:2: DtypeWarning: Columns (1,2,3,10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\u003cipython-input-4-45f683a2eb1a\u003e:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"]},{"name":"stdout","output_type":"stream","text":["Null values in each column:\n"," Booking_ID                    0\n","number of adults            129\n","number of children          129\n","number of weekend nights    256\n","number of week nights       256\n","type of meal                256\n","car parking space           256\n","room type                   256\n","lead time                   256\n","market segment type         256\n","repeated                    256\n","P-C                         257\n","P-not-C                     257\n","average price               257\n","special requests            257\n","date of reservation         257\n","booking status              257\n","dtype: int64\n","\n","Data types of each column:\n"," Booking_ID                   object\n","number of adults             object\n","number of children           object\n","number of weekend nights     object\n","number of week nights       float64\n","type of meal                 object\n","car parking space           float64\n","room type                    object\n","lead time                   float64\n","market segment type          object\n","repeated                     object\n","P-C                         float64\n","P-not-C                     float64\n","average price               float64\n","special requests            float64\n","date of reservation          object\n","booking status               object\n","dtype: object\n"]}],"source":["# Load data\n","data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\n","# Check for null values and data types\n","print(\"Null values in each column:\\n\", data.isnull().sum())\n","print(\"\\nData types of each column:\\n\", data.dtypes)\n","\n","# Strip whitespace from column names and data\n","data.columns = data.columns.str.strip()\n","data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1727969836570,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"scZT2cAv6ELU","outputId":"190ff1df-5347-4b09-f2c4-741191d50af4"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-48-ab1d275ca46e\u003e:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['date of reservation'] = pd.to_datetime(data['date of reservation'], errors='coerce')\n","\u003cipython-input-48-ab1d275ca46e\u003e:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Guests'] = data['number of adults'] + data['number of children']\n","\u003cipython-input-48-ab1d275ca46e\u003e:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce') + pd.to_numeric(data['number of week nights'], errors='coerce')\n","\u003cipython-input-48-ab1d275ca46e\u003e:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\u003cipython-input-48-ab1d275ca46e\u003e:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Ordered Meal Type'] = data['type of meal'].map(meal_type_mapping)\n"]}],"source":["# Handle outliers using IQR\n","Q1 = data['average price'].quantile(0.25)\n","Q3 = data['average price'].quantile(0.75)\n","IQR = Q3 - Q1\n","outlier_condition = (data['average price'] \u003c (Q1 - 1.5 * IQR)) | (data['average price'] \u003e (Q3 + 1.5 * IQR))\n","data = data[~outlier_condition]\n","\n","data['date of reservation'] = pd.to_datetime(data['date of reservation'], errors='coerce')\n","\n","# Feature engineering: Total Guests, Total Nights, Special Request Count\n","data['Total Guests'] = data['number of adults'] + data['number of children']\n","data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce') + pd.to_numeric(data['number of week nights'], errors='coerce')\n","data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\n","# Encode Meal Type\n","meal_type_mapping = {meal: idx for idx, meal in enumerate(data['type of meal'].unique())}\n","data['Ordered Meal Type'] = data['type of meal'].map(meal_type_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1355,"status":"ok","timestamp":1727971875378,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"PEZrRfqu6JZj","outputId":"0e1e49a8-c444-4641-f7fa-9c3609f17720"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['number of adults', 'number of children', 'number of weekend nights',\n","       'number of week nights', 'car parking space', 'lead time',\n","       'market segment type', 'repeated', 'P-C', 'P-not-C', 'average price',\n","       'Total Guests', 'Total Nights', 'Special Request Count',\n","       'Ordered Meal Type', 'reservation_year', 'reservation_month',\n","       'reservation_day'],\n","      dtype='object')\n"]}],"source":["# Select features and target\n","features = data.drop(columns=['Booking_ID', 'booking status', 'type of meal', 'room type', 'special requests'])\n","target = data['booking status']\n","\n","# Convert 'date of reservation' to datetime and handle errors\n","features['date of reservation'] = pd.to_datetime(features['date of reservation'], errors='coerce')\n","\n","# Extract year, month, and day of the week from date of reservation\n","features['reservation_year'] = features['date of reservation'].dt.year\n","features['reservation_month'] = features['date of reservation'].dt.month\n","features['reservation_day'] = features['date of reservation'].dt.dayofweek\n","\n","# Drop the original reservation date column\n","features = features.drop(columns=['date of reservation'])\n","\n","# Update cat_features to include the new date-related features\n","cat_features = ['reservation_year', 'reservation_month', 'reservation_day',\n","                'market segment type', 'repeated guest', 'reserved room type']\n","\n","\n","# Define numeric and categorical features for the ColumnTransformer\n","num_features = ['lead time', 'average price', 'number of adults', 'number of children',\n","                'number of weekend nights', 'number of week nights', 'car parking space',\n","                'Total Guests', 'Total Nights', 'Special Request Count', 'Ordered Meal Type']\n","\n","# Ensure all categorical features are strings\n","for col in cat_features:\n","    if col in features.columns:\n","        features[col] = features[col].astype(str)\n","\n","# Ensure all numeric features are numeric and handle errors\n","for feature in num_features:\n","    if feature in features.columns:\n","        features[feature] = pd.to_numeric(features[feature], errors='coerce')\n","\n","# Impute missing values in numerical features with the mean\n","for feature in num_features:\n","    if feature in features.columns:\n","        features[feature] = features[feature].fillna(features[feature].mean())\n","\n","# Impute missing values in categorical features with the most frequent value\n","for feature in cat_features:\n","    if feature in features.columns:\n","        features[feature] = features[feature].fillna(features[feature].mode()[0])\n","\n","# Check and handle NaN values in the target variable\n","# This line was added to address the potential NaN values in the target\n","target = target.fillna(target.mode()[0])\n","\n","# Print the columns of the features DataFrame to check for inconsistencies\n","print(features.columns)\n","\n","# Create preprocessing pipeline\n","num_pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing numerical values with the mean\n","    ('scaler', StandardScaler())\n","])\n","\n","# Ensure all features are present in the DataFrame before processing\n","num_features = [col for col in num_features if col in features.columns]\n","cat_features = [col for col in cat_features if col in features.columns]\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_pipeline, num_features),  # Use the pipeline for numerical features\n","        ('cat', OneHotEncoder(), cat_features)\n","    ])\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target) # Stratify based on the target variable instead of 'reservation_year'\n","\n","# Convert target variables to strings after train-test split\n","y_train = y_train.astype(str)\n","y_test = y_test.astype(str)\n","\n","# Impute missing values and preprocess training and testing data using the pipeline\n","X_train_transformed = preprocessor.fit_transform(X_train)\n","X_test_transformed = preprocessor.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"s74Hjv9a7I8J"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n","Best Random Forest Accuracy: 0.8404\n"]}],"source":["# Hyperparameter tuning for Random Forest\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [2, 5,10]\n","}\n","\n","grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train_transformed, y_train)\n","\n","best_rf = grid_search.best_estimator_\n","print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n","\n","# Evaluate best model\n","y_pred_best_rf = best_rf.predict(X_test_transformed)\n","accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n","print(f\"Best Random Forest Accuracy: {accuracy_best_rf:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RES8bj4VPmpz"},"outputs":[],"source":["import pickle\n","\n","# Save the trained model\n","with open('best_rf_model.pkl', 'wb') as f:\n","    pickle.dump(best_rf, f)\n","\n","# To load the model later:\n","# with open('best_rf_model.pkl', 'rb') as f:\n","#     loaded_model = pickle.load(f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NHPRWx09BVGk"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5006\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":[" * Ngrok tunnel URL: NgrokTunnel: \"https://3f47-34-168-104-136.ngrok-free.app\" -\u003e \"http://localhost:5006\"\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [04/Oct/2024 16:30:45] \"\u001b[35m\u001b[1mPOST /predict_booking HTTP/1.1\u001b[0m\" 500 -\n"]},{"name":"stdout","output_type":"stream","text":["Received input data: {'lead time': 10, 'average price': 200.5, 'number of adults': 2, 'number of children': 1, 'number of weekend nights': 1, 'number of week nights': 2, 'car parking space': 1, 'Total Guests': 3, 'Total Nights': 3, 'Special Request Count': 2, 'Ordered Meal Type': 1, 'reservation_year': 2024, 'reservation_month': 10, 'reservation_day': 15, 'market segment type': 0, 'repeated guest': 1, 'reserved room type': 2}\n","Input data keys: dict_keys(['lead time', 'average price', 'number of adults', 'number of children', 'number of weekend nights', 'number of week nights', 'car parking space', 'Total Guests', 'Total Nights', 'Special Request Count', 'Ordered Meal Type', 'reservation_year', 'reservation_month', 'reservation_day', 'market segment type', 'repeated guest', 'reserved room type'])\n","Transformed feature array: [[1.000e+01 2.005e+02 2.000e+00 1.000e+00 1.000e+00 2.000e+00 1.000e+00\n","  3.000e+00 3.000e+00 2.000e+00 1.000e+00 2.024e+03 1.000e+01 1.500e+01\n","  0.000e+00 1.000e+00 2.000e+00]]\n","Exception occurred: X has 17 features, but RandomForestClassifier is expecting 8 features as input.\n"]}],"source":["app = Flask(__name__)\n","CORS(app)\n","\n","# Load the pre-trained model\n","model = joblib.load('best_rf_model.pkl')\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    try:\n","        input_data = request.json\n","\n","        # Log received data for debugging\n","        print(\"Received input data:\", input_data)\n","\n","        # Updated required features based on model training\n","        required_features = [\n","            'lead time', 'average price', 'number of adults', 'number of children',\n","            'number of weekend nights', 'number of week nights', 'car parking space',\n","            'Total Guests', 'Total Nights', 'Special Request Count',\n","            'Ordered Meal Type', 'reservation_year', 'reservation_month', 'reservation_day_of_week',\n","            'market segment type', 'repeated guest', 'reserved room type', 'customer type'\n","        ]\n","\n","        # Extract features from the request and create an input array for the model\n","        feature_array = np.array([input_data.get(feature) for feature in required_features]).reshape(1, -1)\n","\n","        # Check if any feature is None and log it\n","        if any(value is None for value in feature_array.flatten()):\n","            return jsonify({'error': 'One or more required features are missing or invalid'}), 400\n","\n","        # Make a prediction using the loaded model\n","        prediction = model.predict(feature_array)[0]\n","\n","        # Return the prediction result\n","        return jsonify({'status': prediction})\n","\n","    except KeyError as e:\n","        # Catch missing keys in the input data\n","        return jsonify({'error': f'Missing key: {str(e)}'}), 400\n","\n","    except Exception as e:\n","        # Log any other exceptions that occur\n","        return jsonify({'error': str(e)}), 500\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":580814,"status":"ok","timestamp":1727969800243,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"JrqAJ1fzBXn1"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5012\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":[" * Ngrok tunnel URL: NgrokTunnel: \"https://8ffa-35-231-73-128.ngrok-free.app\" -\u003e \"http://localhost:5012\"\n"]}],"source":["def start_ngrok():\n","    public_url = ngrok.connect(5006)  # ngrok will listen on port 5000\n","    print(\" * Ngrok tunnel URL:\", public_url)\n","\n","if __name__ == '__main__':\n","    threading.Thread(target=start_ngrok).start()\n","    app.run(port=5006)  # Make sure app.run uses the same port as ngrok\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":726,"status":"ok","timestamp":1727916365206,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"2KUP6mIeOuIy","outputId":"abc2fb5f-70a5-4793-d3b8-9843b2062783"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-82-bf111e8e0452\u003e:11: DtypeWarning: Columns (1,2,3,10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\u003cipython-input-82-bf111e8e0452\u003e:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"]},{"name":"stdout","output_type":"stream","text":["Null values in each column:\n"," Booking_ID                    0\n","number of adults            129\n","number of children          129\n","number of weekend nights    256\n","number of week nights       256\n","type of meal                256\n","car parking space           256\n","room type                   256\n","lead time                   256\n","market segment type         256\n","repeated                    256\n","P-C                         257\n","P-not-C                     257\n","average price               257\n","special requests            257\n","date of reservation         257\n","booking status              257\n","dtype: int64\n","\n","Data types of each column:\n"," Booking_ID                   object\n","number of adults             object\n","number of children           object\n","number of weekend nights     object\n","number of week nights       float64\n","type of meal                 object\n","car parking space           float64\n","room type                    object\n","lead time                   float64\n","market segment type          object\n","repeated                     object\n","P-C                         float64\n","P-not-C                     float64\n","average price               float64\n","special requests            float64\n","date of reservation          object\n","booking status               object\n","dtype: object\n","\n","First few rows of the dataset:\n","   Booking_ID number of adults number of children number of weekend nights  \\\n","0   INN00001                1                  1                        2   \n","1   INN00002                1                  0                        1   \n","2   INN00003                2                  1                        1   \n","3   INN00004                1                  0                        0   \n","4   INN00005                1                  0                        1   \n","\n","   number of week nights  type of meal  car parking space    room type  \\\n","0                    5.0   Meal Plan 1                0.0  Room_Type 1   \n","1                    3.0  Not Selected                0.0  Room_Type 1   \n","2                    3.0   Meal Plan 1                0.0  Room_Type 1   \n","3                    2.0   Meal Plan 1                0.0  Room_Type 1   \n","4                    2.0  Not Selected                0.0  Room_Type 1   \n","\n","   lead time market segment type repeated  P-C  P-not-C  average price  \\\n","0      224.0             Offline        0  0.0      0.0          88.00   \n","1        5.0              Online        0  0.0      0.0         106.68   \n","2        1.0              Online        0  0.0      0.0          50.00   \n","3      211.0              Online        0  0.0      0.0         100.00   \n","4       48.0              Online        0  0.0      0.0          77.00   \n","\n","   special requests date of reservation booking status  \n","0               0.0           10/2/2015   Not_Canceled  \n","1               1.0           11/6/2018   Not_Canceled  \n","2               0.0           2/28/2018       Canceled  \n","3               1.0           5/20/2017       Canceled  \n","4               0.0           4/11/2018       Canceled  \n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset, specifying the encoding\n","data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\n","# Check for null values and data types\n","print(\"Null values in each column:\\n\", data.isnull().sum())\n","print(\"\\nData types of each column:\\n\", data.dtypes)\n","\n","# Strip whitespace from column names and data\n","data.columns = data.columns.str.strip()\n","data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n","\n","# Display first few rows\n","print(\"\\nFirst few rows of the dataset:\\n\", data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1727911977589,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"HmtZjkHhPRja","outputId":"4aa06068-11ba-4dc2-cfd3-f87b0e9037c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-66-dd514f8c324e\u003e:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Guests'] = data['number of adults'] + data['number of children']\n","\u003cipython-input-66-dd514f8c324e\u003e:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce') + pd.to_numeric(data['number of week nights'], errors='coerce')\n","\u003cipython-input-66-dd514f8c324e\u003e:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\u003cipython-input-66-dd514f8c324e\u003e:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Ordered Meal Type '] = data['type of meal'].map(meal_type_mapping)\n"]}],"source":["# Handle outliers using IQR\n","Q1 = data['average price'].quantile(0.25)\n","Q3 = data['average price'].quantile(0.75)\n","IQR = Q3 - Q1\n","outlier_condition = (data['average price'] \u003c (Q1 - 1.5 * IQR)) | (data['average price'] \u003e (Q3 + 1.5 * IQR))\n","data = data[~outlier_condition]\n","\n","# Feature engineering: Total Guests, Total Nights, Special Request Count\n","data['Total Guests'] = data['number of adults'] + data['number of children']\n","# Convert columns to numeric before adding\n","data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce') + pd.to_numeric(data['number of week nights'], errors='coerce')\n","data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\n","# Encode Meal Type\n","meal_type_mapping = {meal: idx for idx, meal in enumerate(data['type of meal'].unique())}\n","data['Ordered Meal Type '] = data['type of meal'].map(meal_type_mapping)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQS1ZhzjPVUi"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","# Select features and target\n","features = data.drop(columns=['Booking_ID', 'booking status', 'type of meal', 'room type', 'special requests'])\n","target = data['booking status']\n","\n","# Define numeric and categorical features for the ColumnTransformer\n","num_features = ['lead time', 'average price', 'number of adults', 'number of children',\n","                'number of weekend nights', 'number of week nights', 'car parking space',\n","                'total of special requests', 'Total Guests', 'Total Nights', 'Special Request Count',\n","                'Ordered Meal Type']\n","cat_features = ['arrival date month', 'market segment type', 'repeated guest', 'is repeated guest',\n","                'reserved room type', 'assigned room type', 'deposit type', 'customer type', 'hotel']\n","\n","# Ensure all num_features are numeric and handle errors\n","for feature in num_features:\n","    if feature in features.columns:\n","        # Convert the column to numeric, replacing errors with NaN\n","        features[feature] = pd.to_numeric(features[feature], errors='coerce')\n","\n","        # Check if the column still contains non-numeric values after conversion\n","        if features[feature].dtype == object:\n","            print(f\"Warning: '{feature}' still contains non-numeric values after conversion. Further investigation needed.\")\n","\n","            # Print unique non-numeric values for debugging\n","            # print(f\"Unique non-numeric values in '{feature}': {features[feature][features[feature].apply(lambda x: isinstance(x, str))].unique()}\")\n","\n","num_features = [col for col in num_features if col in features.columns]\n","cat_features = [col for col in cat_features if col in features.columns]\n","\n","# Create ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_features),\n","        ('cat', OneHotEncoder(), cat_features)\n","    ])\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","y_train = y_train.astype(str)\n","y_test = y_test.astype(str)\n","\n","# Impute NaN values using SimpleImputer before fitting/transforming\n","from sklearn.impute import SimpleImputer # Import SimpleImputer\n","\n","num_pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean')), # Impute missing numerical values with the mean\n","    ('scaler', StandardScaler())\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_pipeline, num_features), # Use the pipeline for numerical features\n","        ('cat', OneHotEncoder(), cat_features)\n","    ])\n","\n","# Preprocess training and testing data\n","X_train_transformed = preprocessor.fit_transform(X_train)\n","X_test_transformed = preprocessor.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":968357,"status":"ok","timestamp":1727913004742,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"3p0xXSyUPcuF","outputId":"7dfbd912-eb99-4b7c-f70d-d10adb3e194a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:pyngrok.process.ngrok:t=2024-10-02T23:36:05+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5005-52af1bd4-4f91-48c7-afbf-d3ec1c9bf380 acceptErr=\"failed to accept connection: Listener closed\"\n"]},{"name":"stdout","output_type":"stream","text":["Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n","Best Random Forest Accuracy: 0.8297\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Hyperparameter tuning for Random Forest\n","param_grid = {\n","    'n_estimators': [50, 100,150, 200],\n","    'max_depth': [10,15, 20, None],\n","    'min_samples_split': [2, 5,8, 10]\n","}\n","grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train_transformed, y_train)\n","\n","best_rf = grid_search.best_estimator_\n","print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n","\n","# Evaluate best model\n","y_pred_best_rf = best_rf.predict(X_test_transformed)\n","accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n","print(f\"Best Random Forest Accuracy: {accuracy_best_rf:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":449121,"status":"ok","timestamp":1727913478579,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"BjGOG2cDPfem","outputId":"2fe63e4f-97fc-4ffa-a751-d4dac22ed87e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy after RFECV feature selection: 0.8223\n","Optimal number of features: 9\n","Selected feature indices: [ True  True  True False  True  True  True  True False False False False\n"," False False  True  True]\n","Selected features:\n","[0, 1, 2, 4, 5, 6, 7, 14, 15]\n","\n","Discarded features:\n","[3, 8, 9, 10, 11, 12, 13]\n"]}],"source":["import pandas as pd\n","from sklearn.feature_selection import RFECV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","\n","# Initialize the RandomForestClassifier\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","# Use StratifiedKFold to maintain class balance during cross-validation\n","cv = StratifiedKFold(n_splits=8)\n","\n","# Initialize RFECV to select the optimal number of features, using accuracy as the scoring metric\n","rfecv = RFECV(estimator=rf_model, step=1, cv=cv, scoring='accuracy')\n","\n","# Fit RFECV to the training data\n","rfecv.fit(X_train_transformed, y_train)\n","\n","# Transform both train and test data based on selected features\n","X_train_selected = rfecv.transform(X_train_transformed)\n","X_test_selected = rfecv.transform(X_test_transformed)\n","\n","# Retrain the model using selected features\n","rf_model.fit(X_train_selected, y_train)\n","\n","# Make predictions and evaluate accuracy\n","y_pred_selected = rf_model.predict(X_test_selected)\n","accuracy_selected = accuracy_score(y_test, y_pred_selected)\n","\n","# Print the accuracy after RFECV feature selection\n","print(f\"Accuracy after RFECV feature selection: {accuracy_selected:.4f}\")\n","\n","# Print the number of selected features and their indices\n","print(f\"Optimal number of features: {rfecv.n_features_}\")\n","print(f\"Selected feature indices: {rfecv.support_}\")\n","\n","# Print all features and indicate which ones were selected\n","feature_names = list(range(X_train_transformed.shape[1]))\n","selected_features = [feature_names[i] for i, is_selected in enumerate(rfecv.support_) if is_selected]\n","discarded_features = [feature_names[i] for i, is_selected in enumerate(rfecv.support_) if not is_selected]\n","\n","print(\"Selected features:\")\n","print(selected_features)\n","\n","print(\"\\nDiscarded features:\")\n","print(discarded_features)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3631,"status":"ok","timestamp":1727963900572,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"YeT9EIQHhOof","outputId":"18ff1b38-7e34-42ec-9194-6af34ed503cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.0.4)\n","Requirement already satisfied: Jinja2\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3.0-\u003eFlask) (2.1.5)\n","Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}],"source":["!pip install Flask pyngrok joblib\n","\n","!ngrok config add-authtoken 2mlBokJkBJ3PSki24C2eu7VNVOl_2udn662gXcUGz7v6DS6TC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7901,"status":"ok","timestamp":1727913526777,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"UZ3DhfVcwbpv","outputId":"fb81acae-1d1d-4daf-a011-fa5ca69e8edf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Requirement already satisfied: Flask\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (3.0.4)\n","Requirement already satisfied: Jinja2\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (3.1.4)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (2.2.0)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (8.1.7)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (2024.8.30)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3.0-\u003eFlask\u003e=0.8-\u003eflask-ngrok) (2.1.5)\n"]}],"source":["!pip install --upgrade flask-ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7833,"status":"ok","timestamp":1727913544541,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"WCNYpVGtDBlG","outputId":"149a1c34-97b8-4463-d9ec-954a1327de57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: flask-cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n","Requirement already satisfied: Flask\u003e=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (2.2.5)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask-cors) (3.0.4)\n","Requirement already satisfied: Jinja2\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask-cors) (3.1.4)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask-cors) (2.2.0)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask-cors) (8.1.7)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3.0-\u003eFlask\u003e=0.9-\u003eflask-cors) (2.1.5)\n"]}],"source":["!pip install flask-cors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2057116,"status":"ok","timestamp":1727916359455,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"RSXHZ-uSrkqI","outputId":"56406bda-d1bc-4ba7-9522-018a64ce64f9"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5006\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":[" * Ngrok tunnel URL: NgrokTunnel: \"https://3fbf-34-133-169-175.ngrok-free.app\" -\u003e \"http://localhost:5006\"\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:12:26] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:12:26] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:14:19] \"OPTIONS /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:14:19] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n"]},{"name":"stdout","output_type":"stream","text":["Received input data: {'lead time': '10', 'average price': '150', 'number of adults': '2', 'number of children': '1', 'number of weekend nights': '2', 'number of week nights': '3', 'required car parking spaces': '0', 'total of special requests': '1', 'Total Guests': 3, 'Total Nights': 5, 'Special Request Count': '1', 'arrival date month': 8, 'market segment type': 'Online', 'repeated guest': 'Yes', 'reserved room type': 'Type 1', 'customer type': 'Hotel 1'}\n","Input data keys: dict_keys(['lead time', 'average price', 'number of adults', 'number of children', 'number of weekend nights', 'number of week nights', 'required car parking spaces', 'total of special requests', 'Total Guests', 'Total Nights', 'Special Request Count', 'arrival date month', 'market segment type', 'repeated guest', 'reserved room type', 'customer type'])\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:14:35] \"OPTIONS /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:14:35] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n"]},{"name":"stdout","output_type":"stream","text":["Received input data: {'lead time': '10', 'average price': '150', 'number of adults': '2', 'number of children': '1', 'number of weekend nights': '2', 'number of week nights': '3', 'required car parking spaces': '0', 'total of special requests': '1', 'Total Guests': 3, 'Total Nights': 5, 'Special Request Count': '1', 'arrival date month': 8, 'market segment type': 'Online', 'repeated guest': 'Yes', 'reserved room type': 'Type 1', 'customer type': 'Hotel 1'}\n","Input data keys: dict_keys(['lead time', 'average price', 'number of adults', 'number of children', 'number of weekend nights', 'number of week nights', 'required car parking spaces', 'total of special requests', 'Total Guests', 'Total Nights', 'Special Request Count', 'arrival date month', 'market segment type', 'repeated guest', 'reserved room type', 'customer type'])\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:35:18] \"OPTIONS /predict HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [03/Oct/2024 00:35:18] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"]},{"name":"stdout","output_type":"stream","text":["Received input data: {'lead time': '10', 'average price': '150', 'number of adults': '2', 'number of children': '2', 'number of weekend nights': '1', 'number of week nights': '1', 'required car parking spaces': '1', 'total of special requests': '1', 'Total Guests': 4, 'Total Nights': 2, 'Special Request Count': '1', 'Ordered Meal Type': 'Meal Plan 1', 'arrival date month': '2018-02-05', 'market segment type': 'Online', 'repeated guest': 'Yes', 'reserved room type': 'Type 1', 'customer type': 'Hotel 1'}\n","Input data keys: dict_keys(['lead time', 'average price', 'number of adults', 'number of children', 'number of weekend nights', 'number of week nights', 'required car parking spaces', 'total of special requests', 'Total Guests', 'Total Nights', 'Special Request Count', 'Ordered Meal Type', 'arrival date month', 'market segment type', 'repeated guest', 'reserved room type', 'customer type'])\n","Transformed feature array: [['10' '150' '2' '2' '1' '1' '1' '1' '4' '2' '1' 'Meal Plan 1'\n","  '2018-02-05' 'Online' 'Yes' 'Type 1' 'Hotel 1']]\n","Exception occurred: could not convert string to float: 'Meal Plan 1'\n"]}],"source":["from flask_cors import CORS\n","from flask import Flask, request, jsonify\n","from pyngrok import ngrok\n","import numpy as np\n","import joblib\n","import threading\n","\n","app = Flask(__name__)\n","CORS(app)\n","\n","# Load the pre-trained model\n","model = joblib.load('/content/best_rf_model.pkl')\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    try:\n","        input_data = request.json\n","\n","        # Log received data for debugging\n","        print(\"Received input data:\", input_data)\n","        print(\"Input data keys:\", input_data.keys())  # Debugging statement\n","\n","        # Required features based on model training\n","        required_features = [\n","            'lead time', 'average price', 'number of adults', 'number of children',\n","            'number of weekend nights', 'number of week nights', 'required car parking spaces',\n","            'total of special requests', 'Total Guests', 'Total Nights', 'Special Request Count',\n","            'Ordered Meal Type', 'arrival date month',\n","            'market segment type', 'repeated guest', 'reserved room type', 'customer type'\n","        ]\n","\n","        # Extract features from the request and create an input array for the model\n","        feature_array = np.array([input_data.get(feature) for feature in required_features]).reshape(1, -1)\n","\n","        # Check if any feature is None and log it\n","        if any(value is None for value in feature_array.flatten()):\n","            return jsonify({'error': 'One or more required features are missing or invalid'}), 400\n","\n","        # Log transformed features to ensure correct input\n","        print(\"Transformed feature array:\", feature_array)\n","\n","        # Make a prediction using the loaded model\n","        prediction = model.predict(feature_array)[0]\n","\n","        # Log the prediction result\n","        print(\"Prediction result:\", prediction)\n","\n","        # Return the prediction result\n","        return jsonify({'status': prediction})\n","\n","    except KeyError as e:\n","        # Catch missing keys in the input data\n","        print(f\"Missing key error: {str(e)}\")\n","        return jsonify({'error': f'Missing key: {str(e)}'}), 400\n","\n","    except Exception as e:\n","        # Log any other exceptions that occur\n","        print(f\"Exception occurred: {str(e)}\")\n","        return jsonify({'error': str(e)}), 500\n","\n","def start_ngrok():\n","    public_url = ngrok.connect(5006)  # ngrok will listen on port 5000\n","    print(\" * Ngrok tunnel URL:\", public_url)\n","\n","if __name__ == '__main__':\n","    threading.Thread(target=start_ngrok).start()\n","    # Use a different port or kill the process using that port\n","    app.run(port=5006)  # Make sure app.run uses the same port as ngrok\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1397,"status":"error","timestamp":1727917282700,"user":{"displayName":"Ahmed Hamisa","userId":"16786437448476838252"},"user_tz":-180},"id":"8JRV9Ucv3z5v","outputId":"b1bf0c6f-aa08-426e-f28c-b113f9103c21"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-87-bb29eadc8af5\u003e:21: DtypeWarning: Columns (1,2,3,10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\u003cipython-input-87-bb29eadc8af5\u003e:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n","\u003cipython-input-87-bb29eadc8af5\u003e:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Guests'] = data['number of adults'] + data['number of children']\n","\u003cipython-input-87-bb29eadc8af5\u003e:36: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce').fillna(0) + \\\n","\u003cipython-input-87-bb29eadc8af5\u003e:38: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\u003cipython-input-87-bb29eadc8af5\u003e:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Ordered Meal Type'] = data['type of meal'].map(meal_type_mapping)\n"]},{"name":"stdout","output_type":"stream","text":["\n","First few rows of the dataset:\n","   Booking_ID number of adults number of children number of weekend nights  \\\n","0   INN00001                1                  1                        2   \n","1   INN00002                1                  0                        1   \n","2   INN00003                2                  1                        1   \n","3   INN00004                1                  0                        0   \n","4   INN00005                1                  0                        1   \n","\n","   number of week nights  type of meal  car parking space    room type  \\\n","0                    5.0   Meal Plan 1                0.0  Room_Type 1   \n","1                    3.0  Not Selected                0.0  Room_Type 1   \n","2                    3.0   Meal Plan 1                0.0  Room_Type 1   \n","3                    2.0   Meal Plan 1                0.0  Room_Type 1   \n","4                    2.0  Not Selected                0.0  Room_Type 1   \n","\n","   lead time market segment type  ...  P-C  P-not-C  average price  \\\n","0      224.0             Offline  ...  0.0      0.0          88.00   \n","1        5.0              Online  ...  0.0      0.0         106.68   \n","2        1.0              Online  ...  0.0      0.0          50.00   \n","3      211.0              Online  ...  0.0      0.0         100.00   \n","4       48.0              Online  ...  0.0      0.0          77.00   \n","\n","   special requests  date of reservation booking status Total Guests  \\\n","0               0.0            10/2/2015   Not_Canceled           11   \n","1               1.0            11/6/2018   Not_Canceled           10   \n","2               0.0            2/28/2018       Canceled           21   \n","3               1.0            5/20/2017       Canceled           10   \n","4               0.0            4/11/2018       Canceled           10   \n","\n","  Total Nights  Special Request Count  Ordered Meal Type  \n","0          7.0                      0                  0  \n","1          4.0                      0                  1  \n","2          4.0                      0                  0  \n","3          2.0                      0                  0  \n","4          3.0                      0                  1  \n","\n","[5 rows x 21 columns]\n"]},{"ename":"TypeError","evalue":"Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'int', 'str']","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 174\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: '\u003c' not supported between instances of 'str' and 'int'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-87-bb29eadc8af5\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 110\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Preprocess training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 110\u001b[0;31m \u001b[0mX_train_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mX_test_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-\u003e 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_empty_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 976\u001b[0;31m         result = self._call_func_on_transformers(\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 )\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 885\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---\u003e 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1310\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-\u003e 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 976\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 99\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcompute_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mcats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 42\u001b[0;31m         return _unique_python(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 179\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;34m\"Encoders require their input argument must be uniformly \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34mf\"strings or numbers. Got {types}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'int', 'str']"]}],"source":["import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.feature_selection import RFECV\n","from sklearn.model_selection import StratifiedKFold\n","import pickle\n","from flask import Flask, request, jsonify\n","from flask_cors import CORS\n","from pyngrok import ngrok\n","import numpy as np\n","import joblib\n","import threading\n","\n","# Load dataset and clean up data\n","data = pd.read_csv('/content/first inten project.csv', encoding='latin1')\n","\n","# Strip whitespace from column names and data\n","data.columns = data.columns.str.strip()\n","data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n","\n","# Handle outliers using IQR\n","Q1 = data['average price'].quantile(0.25)\n","Q3 = data['average price'].quantile(0.75)\n","IQR = Q3 - Q1\n","outlier_condition = (data['average price'] \u003c (Q1 - 1.5 * IQR)) | (data['average price'] \u003e (Q3 + 1.5 * IQR))\n","data = data[~outlier_condition]\n","\n","# Feature engineering: Total Guests, Total Nights, Special Request Count\n","data['Total Guests'] = data['number of adults'] + data['number of children']\n","data['Total Nights'] = pd.to_numeric(data['number of weekend nights'], errors='coerce').fillna(0) + \\\n","                       pd.to_numeric(data['number of week nights'], errors='coerce').fillna(0)\n","data['Special Request Count'] = data['special requests'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n","\n","# Encode Meal Type\n","meal_type_mapping = {meal: idx for idx, meal in enumerate(data['type of meal'].unique())}\n","data['Ordered Meal Type'] = data['type of meal'].map(meal_type_mapping)\n","\n","# Display first few rows\n","print(\"\\nFirst few rows of the dataset:\\n\", data.head())\n","\n","# Select features and target\n","features = data.drop(columns=['Booking_ID', 'booking status', 'type of meal', 'room type', 'special requests'])\n","target = data['booking status']\n","\n","# Define numeric and categorical features for the ColumnTransformer\n","num_features = [\n","    'lead time',\n","    'average price',\n","    'number of adults',\n","    'number of children',\n","    'number of weekend nights',\n","    'number of week nights',\n","    'car parking space',\n","    'Total Guests',\n","    'Total Nights',\n","    'Special Request Count',\n","    'Ordered Meal Type'\n","]\n","cat_features = [\n","    'arrival date month',\n","    'market segment type',\n","    'repeated',\n","    'reserved room type',\n","    'customer type'\n","]\n","\n","# Ensure all num_features are numeric and handle errors\n","for feature in num_features:\n","    if feature in features.columns:\n","        features[feature] = pd.to_numeric(features[feature], errors='coerce')\n","        if features[feature].dtype == object:\n","            print(f\"Warning: '{feature}' still contains non-numeric values after conversion.\")\n","\n","num_features = [col for col in num_features if col in features.columns]\n","cat_features = [col for col in cat_features if col in features.columns]\n","\n","# Create ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_features),\n","        ('cat', OneHotEncoder(), cat_features)\n","    ]\n",")\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","y_train = y_train.astype(str)\n","y_test = y_test.astype(str)\n","\n","# Impute NaN values using SimpleImputer\n","num_pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('scaler', StandardScaler())\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_pipeline, num_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features) # handle_unknown='ignore' added to OneHotEncoder\n","    ]\n",")\n","\n","# Preprocess training and testing data\n","X_train_transformed = preprocessor.fit_transform(X_train)\n","X_test_transformed = preprocessor.transform(X_test)\n","\n","# Hyperparameter tuning for Random Forest\n","param_grid = {\n","    'n_estimators': [50, 100, 150, 200],\n","    'max_depth': [10, 15, 20, None],\n","    'min_samples_split': [2, 5, 8, 10]\n","}\n","grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train_transformed, y_train)\n","\n","best_rf = grid_search.best_estimator_\n","print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n","\n","# Evaluate best model\n","y_pred_best_rf = best_rf.predict(X_test_transformed)\n","accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n","print(f\"Best Random Forest Accuracy: {accuracy_best_rf:.4f}\")\n","\n","# Feature selection with RFECV\n","rf_model = RandomForestClassifier(random_state=42)\n","cv = StratifiedKFold(n_splits=8)\n","rfecv = RFECV(estimator=rf_model, step=1, cv=cv, scoring='accuracy')\n","rfecv.fit(X_train_transformed, y_train)\n","\n","# Transform both train and test data based on selected features\n","X_train_selected = rfecv.transform(X_train_transformed)\n","X_test_selected = rfecv.transform(X_test_transformed)\n","\n","# Retrain the model using selected features\n","rf_model.fit(X_train_selected, y_train)\n","\n","# Make predictions and evaluate accuracy\n","y_pred_selected = rf_model.predict(X_test_selected)\n","accuracy_selected = accuracy_score(y_test, y_pred_selected)\n","\n","# Print the accuracy after RFECV feature selection\n","print(f\"Accuracy after RFECV feature selection: {accuracy_selected:.4f}\")\n","\n","# Print the number of selected features and their indices\n","print(f\"Optimal number of features: {rfecv.n_features_}\")\n","print(f\"Selected feature indices: {rfecv.support_}\")\n","\n","# Print all features and indicate which ones were selected\n","feature_names = list(range(X_train_transformed.shape[1]))\n","selected_features = [feature_names[i] for i, is_selected in enumerate(rfecv.support_) if is_selected]\n","discarded_features = [feature_names[i] for i, is_selected in enumerate(rfecv.support_) if not is_selected]\n","\n","print(\"Selected features:\")\n","print(selected_features)\n","\n","print(\"\\nDiscarded features:\")\n","print(discarded_features)\n","\n","# Save the trained model\n","with open('best_rf_model.pkl', 'wb') as f:\n","    pickle.dump(best_rf, f)\n","\n","# Flask application setup\n","app = Flask(__name__)\n","CORS(app)\n","\n","# Load the pre-trained model\n","model = joblib.load('best_rf_model.pkl')\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    try:\n","        input_data = request.json\n","\n","        # Log received data for debugging\n","        print(\"Received input data:\", input_data)\n","\n","        # Required features based on model training\n","        required_features = [\n","            'lead time',\n","            'average price',\n","            'number of adults',\n","            'number of children',\n","            'number of weekend nights',\n","            'number of week nights',\n","            'car parking space',\n","            'Total Guests',\n","            'Total Nights',\n","            'Special Request Count',\n","            'Ordered Meal Type',\n","            'arrival date month',\n","            'market segment type',\n","            'repeated guest',\n","            'reserved room type',\n","            'customer type'\n","        ]\n","\n","        # Extract features from the request and create an input array for the model\n","        feature_array = np.array([input_data.get(feature) for feature in required_features]).reshape(1, -1)\n","\n","        # Check if any feature is None and log it\n","        if any(value is None for value in feature_array.flatten()):\n","            return jsonify({'error': 'One or more required features are missing or invalid'}), 400\n","\n","        # Log transformed features to ensure correct input\n","        print(\"Transformed feature array:\", feature_array)\n","\n","        # Make a prediction using the loaded model\n","        prediction = model.predict(feature_array)[0]\n","\n","        # Log the prediction result\n","        print(\"Prediction result:\", prediction)\n","\n","        # Return the prediction result\n","        return jsonify({'status': prediction})\n","\n","    except KeyError as e:\n","        print(f\"Missing key error: {str(e)}\")\n","        return jsonify({'error': f'Missing key: {str(e)}'}), 400\n","\n","    except Exception as e:\n","        print(f\"Exception occurred: {str(e)}\")\n","        return jsonify({'error': str(e)}), 500\n","\n","def start_ngrok():\n","    public_url = ngrok.connect(5006)\n","    print(\" * Ngrok tunnel URL:\", public_url)\n","\n","if __name__ == '__main__':\n","    threading.Thread(target=start_ngrok).start()\n","    app.run(port=5006)\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}